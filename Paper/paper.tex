\documentclass[
12pt, % Main document font size
a4paper, % Paper type, use 'letterpaper' for US Letter paper
oneside, % One page layout (no page indentation)
]{llncs}
% \usepackage[german]{babel}
\title{Declarative Pearl: Lightweight Probabilistic Programming in Curry}
\author{Sandra Dylus}
\institute{Institut f\"ur Informatik, Christian-Albrechts-Universi\"at zu Kiel\\\email{sad@informatik.uni-kiel.de}}

\newcommand{\code}[1]{{\texttt{#1}}}

\begin{document}
\maketitle

\begin{abstract}
  Lorem ipsum
\end{abstract}

\section{Introduction}
There are many probabilistic languages around these days; a progress
that started longer than a decade ago, but is currently especially
active. %
These languages have their origin either in functional, logic or
imperative programming, i.e., you can choose a language based on your
favourite paradigm. %
Besides newly developed languages, a few libraries for probabilistic
programming have seen the light of day as well. %
These languages (stand-alone or DSL) all come with a handful of
useful tools (functions and stuff) to work with probabilistic values
and distributions as well as inference algorithms to solve
probabilistic models that use these values and distributions. %
That said, there is a large subset that all these languages have in
common, dispite their different approaches on semantic, syntax as well
as goals and range of usage, respectively. %
This subset is rather of practical nature and not of big intereset
from a PL researcher perspective: every good library or programming
language needs a handful of primitives and predefined functions, but
they are not the heart of this piece of software. %

In case of probabilistic programming languages and libraries, we need
to look at the implementation of the actual semantic behaviour -- what
can we express with probabilistic languages and how can we interpret
such an expression? %
What is the intuition behind probability in the context of programming
and what is its meaning? %

The main goal of probabilistic programming is to open the door for a
wide range of groups that want to evaluate probabilistic models: data
scientists, domain experts and other developers. %
Probabilistic programming languages want to minimise the burden for
non-experts (in the area of machine learning and co) to design their
own model and run algorithm on their data. %
These languages already provide a rich set of primitives and most
importantly inference algorithms that are built upon the results of
experts. %
Thus, a predefined and well-elaborated toolset simplifies the access
to machine learning, because technical details can be ignored. %

Contributions:
\begin{itemize}
\item We present \emph{PFLP} a lightweight library for probabilistic
  programming in the functional logic language Curry. %
  The library's core consists of ... data structures as well as
  ... functions to work on these strucutres, overall the library needs
  less than 30 lines of code. %
\item We can reduce the library code to such a minimum by reusing Curry's
  semantic. %
  The best part is: no further mechanisms are necessary to enable
  probabilistic computations in Curry. %
  That said, we show high connections between current probability
  programming languages and Curry, including lazy evaluation,
  nondeterministic values as well as corresponding built-in search
  abilities and call-time choice. %
\item We present examples that emphasise the benefits of Curry's
  representation of nondeterminsm, which enables early pruning of the
  search space, compared to Haskell's MonadPlus instance for lists,
  which is often used to model nondeterminism. %
\end{itemize}

\section{The Problem}

Experts often state that you do not need to be a rocket scientist in
order to make sense of research results; however, in the area of
machine learning, beginners often face difficulties to use the tools
and current knowledge for their own project. %
That is, beginners need to inverse many hours to digest technical
details before they can actually make use of top-of-the-art models and
algorithms. %

In the field of programming languages, the community often tries to
generalise and simplify commen concepts and repetative structures. %
Fortunately, the rising collaboration between ML and PL communities
has produced a number of programming languages and libraries for
probabilistic programming that aim at minimising the obstacle to use
practicle results of ML, thus, empower more users to apply ML
techniques to their problems. %


For instance, a typical problem in the field of \emph{Bayesian
  Network}s is to transfer a given model (e.g., a conditional
probability table) into code in order to evaluation the model for a
given data set. %
Such an evaluation can range from stating queries to documenting
observations to apply learning algorithms. %

\begin{figure}
\caption{Bayesian network with conditional probability table for \emph{alarm}-scenario}
\end{figure}

We can model this bayesian network with the following code. %

\begin{verbatim}
earthquake = bernoulli 0.2
burglary   = bernoulli 0.7

alarm True  True  = bernoulli 0.9
alarm True  False = bernoulli 0.8
alarm False True  = bernoulli 0.1
alarm False False = bernoulli 0.0
\end{verbatim}

The definition for the probabilistic functions \code{earthquake},
\code{burglary} and \code{alarm} follow straight-forward from the
scheme of the given model. %
The function \code{bernoulli} yields a probabilistic value that is
\code{True} with probability given by the first argument and
\code{False} with probability $1 - prob$. %

\begin{verbatim}
bernoulli prob = mkDist True prob
bernoulli prob = mkDist False (1.0 - prob)
\end{verbatim}

\section{The Idea}

\begin{itemize}
\item we model probabilistic values with nondeterminstic values -- a
  probabilistic value is a pair of a value and its probability; a
  probabilistic value %

\begin{verbatim}
biasedCoin = (True, 0.3)
biasedCoin = (False, 0.7)
\end{verbatim}

  Rules with overlapping patterns on the left-hand side are one way to
  define nondeterministic functions in Curry. %
  Alternatively, Curry provides an explicite choice operator \code{?}
  that chooses nondeterministic between its first and second
  argument. %

\begin{verbatim}
coin = (True ? False,0.5)
\end{verbatim}

\item Working within a host language enables us to focus on the
  problem itself and frees us from reimplementing standard primitives
  (IO, data structures), essential design decisions (syntax,
  parser). %
  Based on which criteria do you choose the host language? %
  As for probabilistic languages that started growing over time,
  libraries that enable probablistic programming exist in the whole
  variety of paradigms: declarative as well as imperative. %
  For a start, you obviously choose the paradigm that has the clearest
  structure and enables straight-forward programming. %
  We want to address a wide range of developers and even
  non-PL-experts, thus, we choose a paradigm than can be learnt
  easily. %
  Thus, obvioulsy, you choose a declarative programming language. %
  By choosing Curry, we argue that it is sufficient to reuse built-in
  features in order to cover the essence of probabilistic programs,
  especially its semantic. %
  
\end{itemize}

\section{The Details}

\begin{itemize}

\item We treat nondeterministic values like \emph{normal} values, that
  is, we can test predicates on nondeterministic values in order to
  filter unwanted results. %

\begin{verbatim}
filterDist :: (a -> Bool) -> Dist a -> Dist a
filterDist p d | p (value d) = d
\end{verbatim}

  Such a filter is often called \emph{partial identity} and a common
  functional logic design pattern \cite{funcLogPattern}, additionaly,
  it corresponds to notion of observing a probabilistic value and is a
  standard primitive in probabilistic programming languages. %
 
\item Each nondeterministic choice corresponds to a branch in the
  search tree. %
  When we evaluate the search tree, we start at the root of the search
  tree and go along a path in that tree: we decide for each branch
  which child to take next. %
  Additionally, we keep track of each decision we make in order to
  repeat a decision in case it occurs several times at different
  positions within the search tree. %
  However, we have to distinct between values that are choosen
  randomly values that share the decision. %
  This distinction is very natural in Curry: a let-binding forces to
  share decisions on probabilistic values. %

\begin{verbatim}
plus :: Dist Int -> Dist Int -> Dist Int
plus dI1 dI2 = (+) <$> dI1 <*> dI2

doubleCoinWithUnexpectedOutcome =
  coin `plus` coin

doubleCoin =
  let c = coin
  in c `plus` c
\end{verbatim}

\item The choice-operator comes in handy to simplify the corresponding
  search tree. %
  This benefit becomes more clear with the following code examples. %

\begin{verbatim}
coin' = (True, 0.5) ? (False, 0.5)

coin = (True ? False, 0.5)
\end{verbatim}

  There is no semantic difference between the first and second
  definition, however, the corresponding search trees indeed differ. %

  Choice (True, 0.5) (False, 0.5)\\%
  (Choice True False, 0.5)\\%

  The definition of \code{coin'} consists of an expression with a
  nondeterminstic choice on top-level position, whereas the definition
  of \cote{coin} generalises the common parts of the two possible
  values and uses the nondeterminism in a deeper position. %


\item We can benefit from lazy evaluation: a given search tree is only
  evaluated if really needed and only the parts that are essential for
  the given query, e.g., observations can rule out whole branches
  early. %

\end{itemize}

\section{Related Work}

\section{Conclusion and Future Work}

\bibliography{/Users/sad/Documents/Papers/used}
\bibliographystyle{plain}
\end{document}